{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning, training and testing regularized logistic regression models for predicting college enrollment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if packages not installed, install them\n",
    "# import pip\n",
    "# pip.main(['install', numpy]) \n",
    "# pip.main(['install', pandas]) \n",
    "# pip.main(['install', sklearn]) \n",
    "# pip.main(['install', matplotlib]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.externals.six import StringIO   \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.loadtxt('dat1_collen.csv', delimiter=',') #reading in the 53 predictors for college enrolmment\n",
    "print('Dimension of X is {}'.format(X.shape))\n",
    "X[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collen=np.loadtxt('collen.csv', delimiter=',')  #reading in the college enrollment outcome variable\n",
    "print('Dimension of collen is {}'.format(collen.shape))\n",
    "collen[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=np.loadtxt('weights4_collen.csv', delimiter=',') #reading in public data weights at Wave IV\n",
    "weights[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying nested cross-validation here (5-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratify based on the level of the outcome; then randomly split them into 5 folds for traning--testing\n",
    "skf = StratifiedKFold(n_splits=5, random_state = 666, shuffle= True)\n",
    "skf.get_n_splits(X, collen)\n",
    "train_indices=[]\n",
    "test_indices=[]\n",
    "for train_index, test_index in skf.split(X, collen):\n",
    "    train_indices.append(train_index)\n",
    "    test_indices.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted 5-fold cross-validation\n",
    "def cross_val_scores_weighted(model, X, y, weights, cv=5, metrics=[sklearn.metrics.accuracy_score]):\n",
    "    skf = StratifiedKFold(n_splits=cv, random_state = 66, shuffle= True)\n",
    "    skf.get_n_splits(X, y)\n",
    "    scores = [[] for metric in metrics]\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        model_clone = sklearn.base.clone(model)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        weights_train, weights_test = weights[train_index], weights[test_index]\n",
    "        #print(weights[train_index], weights[test_index])\n",
    "        model_clone.fit(X_train,y_train,sample_weight=weights_train)\n",
    "        y_pred = model_clone.predict(X_test)\n",
    "        for i, metric in enumerate(metrics):\n",
    "            score = metric(y_test, y_pred, sample_weight = weights_test)\n",
    "            scores[i].append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test 1 (i.e., CV1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train_indices[0]\n",
    "test1 = test_indices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner-loop cross-validation: tuning regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regs=[0.001,0.002, 0.01,0.02,0.1,0.2,1,2,10,20,100,200,1000] #1/lambda\n",
    "cv1_accuracy = [] # container for training data accuracy\n",
    "for Reg in Regs:\n",
    "    print(Reg)\n",
    "    lr = LogisticRegression(random_state = 66, C = Reg)\n",
    "    scores = cross_val_scores_weighted(model=lr, X=X[train1], y=collen[train1], weights = weights[train1], cv=5)\n",
    "    cv1_accuracy.append(np.mean(scores))\n",
    "\n",
    "optimal_Reg1 = Regs[cv1_accuracy.index(max(cv1_accuracy))] \n",
    "print(optimal_Reg1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimal_Reg1, max(cv1_accuracy))\n",
    "plt.plot(range(len(Regs)), cv1_accuracy)\n",
    "plt.ylabel('5-fold cross validation accuracy (training data)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back to train & test (outer loop): using the best regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = LogisticRegression(random_state = 666, C = optimal_Reg1)\n",
    "lr1.fit(X[train1], collen[train1], sample_weight = weights[train1])\n",
    "lr1.score(X[test1], collen[test1], sample_weight=weights[test1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_true = [ int(i) for i in collen[test1] ], \n",
    "              y_score = lr1.predict_proba(X[test1])[:, 1], sample_weight = weights[test1])\n",
    "#accuracy score for CV1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test 2 (i.e., CV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train_indices[1]\n",
    "test2 = test_indices[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Inner-loop cross-validation: tuning regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regs=[0.001,0.002, 0.01,0.02,0.1,0.2,1,2,10,20,100,200,1000]\n",
    "cv2_accuracy = [] # container for training data errors\n",
    "for Reg in Regs:\n",
    "    print(Reg)\n",
    "    lr = LogisticRegression(random_state = 66, C = Reg)\n",
    "    scores = cross_val_scores_weighted(model=lr, X=X[train2], y=collen[train2], weights = weights[train2], cv=5)\n",
    "    cv2_accuracy.append(np.mean(scores))\n",
    "\n",
    "optimal_Reg2 = Regs[cv2_accuracy.index(max(cv2_accuracy))] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(optimal_Reg2, max(cv2_accuracy))\n",
    "plt.plot(range(len(Regs)), cv2_accuracy)\n",
    "plt.ylabel('5-fold cross validation accuracy (training data)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back to train & test (outer loop): using the best regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression(random_state = 666, C = optimal_Reg2)\n",
    "lr2.fit(X[train2], collen[train2], sample_weight = weights[train2])\n",
    "lr2.score(X[test2], collen[test2], sample_weight=weights[test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_true = [ int(i) for i in collen[test2] ], \n",
    "              y_score = lr2.predict_proba(X[test2])[:, 1], sample_weight = weights[test2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test 3 (i.e., CV3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = train_indices[2]\n",
    "test3 = test_indices[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner-loop cross-validation: tuning regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regs=[0.001,0.002, 0.01,0.02,0.1,0.2,1,2,10,20,100,200,1000]\n",
    "cv3_accuracy = [] # container for training data errors\n",
    "for Reg in Regs:\n",
    "    print(Reg)\n",
    "    lr = LogisticRegression(random_state = 66, C = Reg)\n",
    "    scores = cross_val_scores_weighted(model=lr, X=X[train3], y=collen[train3], weights = weights[train3], cv=5)\n",
    "    cv3_accuracy.append(np.mean(scores))\n",
    "\n",
    "optimal_Reg3 = Regs[cv3_accuracy.index(max(cv3_accuracy))] \n",
    "print(optimal_Reg3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimal_Reg3, max(cv3_accuracy))\n",
    "plt.plot(range(len(Regs)), cv3_accuracy)\n",
    "plt.ylabel('5-fold cross validation accuracy (training data)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back to train & test (outer loop): using the best regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3 = LogisticRegression(random_state = 666, C = optimal_Reg3)\n",
    "lr3.fit(X[train3], collen[train3], sample_weight = weights[train3])\n",
    "lr3.score(X[test3], collen[test3], sample_weight=weights[test3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_true = [ int(i) for i in collen[test3] ], \n",
    "              y_score = lr3.predict_proba(X[test3])[:, 1], sample_weight = weights[test3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test 4 (i.e., CV4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train4 = train_indices[3]\n",
    "test4 = test_indices[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner-loop cross-validation: tuning regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regs=[0.001,0.002, 0.01,0.02,0.1,0.2,1,2,10,20,100,200,1000]\n",
    "cv4_accuracy = []\n",
    "for Reg in Regs:\n",
    "    print(Reg)\n",
    "    lr = LogisticRegression(random_state = 66, C = Reg)\n",
    "    scores = cross_val_scores_weighted(model=lr, X=X[train4], y=collen[train4], weights = weights[train4], cv=5)\n",
    "    cv4_accuracy.append(np.mean(scores))\n",
    "\n",
    "optimal_Reg4 = Regs[cv4_accuracy.index(max(cv4_accuracy))] \n",
    "print(optimal_Reg4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(optimal_Reg4, max(cv4_accuracy))\n",
    "plt.plot(range(len(Regs)), cv4_accuracy)\n",
    "plt.ylabel('5-fold cross validation accuracy (training data)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back to train & test (outer loop): using the best regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr4 = LogisticRegression(random_state = 666, C = optimal_Reg4)\n",
    "lr4.fit(X[train4], collen[train4], sample_weight = weights[train4])\n",
    "lr4.score(X[test4], collen[test4], sample_weight=weights[test4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_true = [ int(i) for i in collen[test4] ], \n",
    "              y_score = lr4.predict_proba(X[test4])[:, 1], sample_weight = weights[test4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test 5 (i.e., CV5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train5 = train_indices[4]\n",
    "test5 = test_indices[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner-loop cross-validation: tuning regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regs=[0.001,0.002, 0.01,0.02,0.1,0.2,1,2,10,20,100,200,1000]\n",
    "cv5_accuracy = [] # container for training data errors\n",
    "for Reg in Regs:\n",
    "    print(Reg)\n",
    "    lr = LogisticRegression(random_state = 66, C = Reg)\n",
    "    scores = cross_val_scores_weighted(model=lr, X=X[train5], y=collen[train5], weights = weights[train5], cv=5)\n",
    "    cv5_accuracy.append(np.mean(scores))\n",
    "\n",
    "optimal_Reg5 = Regs[cv5_accuracy.index(max(cv5_accuracy))] \n",
    "print(optimal_Reg5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimal_Reg5, max(cv5_accuracy))\n",
    "plt.plot(range(len(Regs)), cv5_accuracy)\n",
    "plt.ylabel('5-fold cross validation accuracy (training data)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back to train & test (outer loop): using the best regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr5 = LogisticRegression(random_state = 666, C = optimal_Reg5)\n",
    "lr5.fit(X[train5], collen[train5], sample_weight = weights[train5])\n",
    "lr5.score(X[test5], collen[test5], sample_weight=weights[test5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_true = [ int(i) for i in collen[test5] ], \n",
    "              y_score = lr5.predict_proba(X[test5])[:, 1], sample_weight = weights[test5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
